for (i in 1:N_ITER) {
# Etape 1: je genere un tableau tout comme mon tableau de base
# SAUF que les donnÃªs representent l'hypothese que il n'y
# a rien que le pur hasard qui donne lieu aux differences
# constatÃªes
spr_fake <- randomiser_var(spr, "logRT")
# Etape 2: je genere une statistique de test
# pour ces donnÃªes inventÃªs
#stat <- diff_medianes(spr_fake, "Condition", "Grammatical", "Ungrammatical", "logRT")
stat <- diff_moyennes(spr_fake, "Condition", "Grammatical", "Ungrammatical", "logRT")
statistiques[i] <- stat
}
stat_obs <- mean(spr_gram$logRT) - mean(spr_ungram$logRT)
hist(statistiques, col="yellow", xlim=c(-0.2, 0.2))
abline(v=stat_obs, col="blue")
arbuthnot <- readr::read_csv("arbuthnot.csv")
arbuthnot <- readr::read_csv("arbuthnot.csv")
arbuthnot <- readr::read_csv("arbuthnot.csv")
# On constate que, de maniere systematique, il y a plus
# de garcons qui naissent que de filles
plot(boys ~ year, data=arbuthnot, ylim=c(2000, 9000))
plot(girls ~ year, data=arbuthnot, ylim=c(2000, 9000))
# Plotter garcons et filles sur le meme graphique
arbuthnot_long <- tidyr::gather(arbuthnot,
value="births",
key="sex",
boys, girls)
ggplot2::ggplot(arbuthnot_long,
ggplot2::aes(y=births, x=year,
colour=sex)) +
ggplot2::geom_point() +
ggplot2::scale_color_brewer(type="qual", palette="Set1")
# Compter nombre d'annees qu'il y a plus de garcons
# que de filles
n_male_years <- sum(arbuthnot$boys > arbuthnot$girls)
# On pourrait generer un dataset artificiel sous l'hypothese que
# les naissances sont equiprobable
# Le principe d'un test de signe est qu'on peut simplement
# reflechir au resume suivant d'un tel dataset:
# le nombre d'annees qu'il y a plus de garcons que de filles
rbinom(1, 82, 0.5)
rbinom(1, 82, 0.5)
rbinom(1, 82, 0.5)
rbinom(1, 82, 0.5)
# Si on echantillonne plusieurs fois sous cette hypothese
# nous pouvons voir les predictions en terme de nombre
# d'annees "garcon" (i.e. plus de garcon que de filles)
stats_hypothese_nulle <- rbinom(1000, 82, 0.5)
hist(stats_hypothese_nulle, xlim=c(24,82))
# On voit que notre resultat est tres loin des predictions
# de cette hypothese
abline(v=n_male_years)
# Probabilite d'avoir exactement 82 annees garcons
# sous cette hypothese
dbinom(n_male_years, 82, 0.5)
# on fait presque cette demarche. L'idee etant que
# un resultat de 82 serait tres inattendu sous
# l'hypothese d'equiprobabilite, on calcule la probabilite
# d'un resultat comme celui qu'on a vu OU PIRE
# pour cette hypothese. Donc, ce qu'on ferait si
# on essayait d'evaluer l'hypothese avec cette demarche
# mais on avait constate 80 annees garcon (et non pas 82)
# est qu'on calculerait la probabilite d'au moins
# 80 annees garcon (vu que 81, 82 sont encore plus
# douteux comme resultat)
1 - pbinom(81, 82, 0.5)
# Ici on nous dit que la probabilite est de zero, on
# sait que ce n'est pas le cas. Ca doit etre un probleme
# numerique. Voila de la magie pour regler le probleme.
pbinom(81, 82, 0.5, lower.tail = FALSE)
pbinom(81, 82, 0.5, lower.tail = FALSE, log=TRUE)
# Il existe des seuils standards pour passer a une
# p-value a la certitude totale, ce qui sont, nautrellement,
# artificielles, parce qu'il n'y a pas de certitude.
# Mais les gens sont "contents" de supposer qu'une p-value
# en dessous de 0.05 (1/20) est raisonnablement improbable
# (meme si, si on prend le cas actuel, on arrive a ca
# deja ayant juste 49 annees masculines, ce qui est quand
# meme pas si improbable que ca)
pbinom(48, 82, 0.5, lower.tail = FALSE)
# Exemples de loi probabilistes
sample_bernoulli <- function(p) {
return(sample(c("FACE", "PILE"), 1, prob=c(p, 1-p)))
}
sample_binomial <- function(n, p) {
successes <- 0
for (i in 1:n) {
coin_flip <- sample_bernoulli(p)
if (coin_flip == "FACE") {
successes <- successes + 1
}
}
return(successes)
}
sample_binomial(82, 0.5)
sample_binomial(82, 0.5)
sample_binomial(82, 0.5)
# Loi Poisson-binomiale est comme une loi binomiale
# mais avec des probabilites potentiellement differente
# sur chaque essai de la sequence d'essais Bernoullis
sample_poisson_binomial <- function(p_vec) {
n <- length(p_vec)
successes <- 0
for (i in 1:n) {
coin_flip <- sample_bernoulli(p_vec[i])
if (coin_flip == "FACE") {
successes <- successes + 1
}
}
return(successes)
}
# Pour montrer ce que ca donne je vais generer
# des probabilites aleatoirement
# Juste pour voir ce qui se passe, je genere
# des probabilites <= 0.50, donc, la piece a toujours
# une probabilite plus elevee de tomber PILE
probabilites <- runif(60, min=0, max=0.50)
poisson_binomial_samples <- rep(0, 10000)
for (i in 1:10000) {
poisson_binomial_samples[i] <- sample_poisson_binomial(probabilites)
}
hist(poisson_binomial_samples)
sample_1 <- rnorm(40, 0, 1)
sample_2 <- rnorm(40, 12, 12)
hist(c(sample_1, sample_2), breaks=40)
# Statistique t qui nous sert aussi comme
# statistique de test quand on cherche a
# detecter une difference en tendance generale
# entre deux groupes d'observations
t_stat <- function(x1, x2) {
diff_in_means <- mean(x1) - mean(x2)
n1 <- length(x1)
n2 <- length(x2)
variance_term <- sqrt(var(x1)/n1 +
var(x2)/n2)
diff_in_means/variance_term
}
sample_1b <- rnorm(5, 0, 10)
sample_2b <- rnorm(7, 4, 20)
hist(c(sample_1b, sample_2b), breaks=40)
position_globale <- mean(c(sample_1b, sample_2b))
N_ITER <- 9999
statistiques <- c()
for (i in 1:N_ITER) {
sample_1_h0 <- rnorm(5, position_globale, 10)
sample_2_h0 <- rnorm(7, position_globale, 20)
stat <- t_stat(sample_1_h0, sample_2_h0)
statistiques[i] <- stat
}
hist(statistiques)
abline(v=t_stat(sample_1b, sample_2b), col="red")
# Si tout ce que je cherche a falsifier est l'hypothese
# qu'il n'y a pas de difference systematique dans la
# position des groupes - peu importe si le groupe 1
# ou le groupe 2 est le plus eleve -
# j'aimerais compter le nombre de fois que j'arrive
# a une statistique aussi extreme dans l'un des deux
# sens - positif ou negatif - sous l'hypothese
# de manque de difference systematique en position
abline(v=-t_stat(sample_1b, sample_2b), col="red")
# Je calcule le pourcentage de tels cas dans mon
# echantillon,
(sum(abs(statistiques) > abs(t_stat(sample_1b, sample_2b))) + 1)/(N_ITER + 1)
# Cette version en R se base sur la loi theorique t,
# qui suppose que les deux groupes suivent vraiment
# une loi normale. Mais ce n'est pas generalement tres grave;
# en cas de doute, on peut faire autre chose (e.g., un
# test de permutation), mais pour des differences de position
# entre deux groupes, le test t est robuste a la supposition
# de normalite
t.test(sample_1b, sample_2b, var.equal = FALSE)
# Si je fais la meme chose sur le premier echantillon,
position_globale_a <- mean(c(sample_1, sample_2))
N_ITER <- 9999
statistiques_a <- c()
for (i in 1:N_ITER) {
sample_1a_h0 <- rnorm(40, position_globale_a, 1)
sample_2a_h0 <- rnorm(40, position_globale_a, 12)
stat <- t_stat(sample_1a_h0, sample_2a_h0)
statistiques_a[i] <- stat
}
hist(statistiques_a, xlim=c(-6,6))
abline(v=t_stat(sample_1, sample_2), col="red")
(sum(abs(statistiques_a) > abs(t_stat(sample_1, sample_2))) + 1)/(N_ITER + 1)
t.test(sample_1, sample_2, var.equal = FALSE)
# J'avais une difference entre deux conditions
library(magrittr)
spr_summary <- spr %>%
dplyr::group_by(Condition) %>%
dplyr::summarize(meanLogRT=mean(logRT),
medianLogRT=median(logRT))
ggplot2::ggplot(spr, ggplot2::aes(x=logRT)) +
ggplot2::geom_histogram(fill="lightgrey",
colour="black",
binwidth = 0.2) +
ggplot2::geom_vline(data=spr_summary,
ggplot2::aes(xintercept=meanLogRT)) +
ggplot2::geom_vline(data=spr_summary,
ggplot2::aes(xintercept=medianLogRT),
lty="dashed") +
ggplot2::facet_grid(Condition ~ .)
# On peut generer un cas un peu plus artificiel
# qui se comporte de cette facon la.
linear <- NULL
for (frequence in 2:9) {
new_response <- sample(spr_ungram$logRT, replace=TRUE) -
frequence*0.5
new_data <- tibble::tibble(logRT=new_response,
freq=frequence)
linear <- dplyr::bind_rows(linear, new_data)
}
# Je fais le meme type de graphique
linear_summary <- linear %>%
dplyr::group_by(freq) %>%
dplyr::summarize(meanLogRT=mean(logRT),
medianLogRT=median(logRT))
ggplot2::ggplot(linear, ggplot2::aes(x=logRT)) +
ggplot2::geom_histogram(fill="lightgrey",
colour="black",
binwidth = 0.2) +
ggplot2::geom_vline(data=linear_summary,
ggplot2::aes(xintercept=meanLogRT)) +
ggplot2::geom_vline(data=linear_summary,
ggplot2::aes(xintercept=medianLogRT),
lty="dashed") +
ggplot2::facet_grid(freq ~ .)
# Il est plus convenable de voir les
# choses d'une autre facon, notamment de
# visualiser non pas par facet mais sur deux
# axes, RT vs frequence
ggplot2::ggplot(linear, ggplot2::aes(y=logRT,
x=freq)) +
ggplot2::geom_point()
# La pente de la ligne que j'ai construite
# est de -0.5. Pour plotter la ligne il suffit
# de trouver l'intercept, qui va etre de
intercept <- 6.314393 + 0.5
ggplot2::ggplot(linear, ggplot2::aes(y=logRT,
x=freq)) +
ggplot2::geom_point() +
ggplot2::geom_abline(intercept=intercept,
slope=-0.5)
# Ce n'est pas le cas tous les effets
# d'une variable sur une autre sont lineaires.
# On peut facilement avoir des effets
# non-lineaires.
nonlinear_1 <- NULL
for (explanatory in 1:9) {
new_response <- sample(spr_ungram$logRT,
replace=TRUE) +
cos(explanatory)*0.5
new_table <- tibble::tibble(Explanatory=explanatory,
Response=new_response)
nonlinear_1 <- dplyr::bind_rows(nonlinear_1,
new_table)
}
nonlinear_1_summary <- nonlinear_1 %>%
dplyr::group_by(Explanatory) %>%
dplyr::summarize(meanResponse=mean(Response),
medianResponse=median(Response)) %>%
dplyr::ungroup()
ggplot2::ggplot(nonlinear_1,
ggplot2::aes(x=Response)) +
ggplot2::geom_histogram(fill="lightgrey",
colour="black",
binwidth=0.2) +
ggplot2::geom_vline(data=nonlinear_1_summary,
ggplot2::aes(xintercept=meanResponse)) +
ggplot2::geom_vline(data=nonlinear_1_summary,
ggplot2::aes(xintercept=medianResponse),
lty="dashed") +
ggplot2::facet_grid(Explanatory ~ .)
# Critere de squared error: l'idee est qu'on cherche
# une ligne (m = pente, b = intercepte) qui est
# la plus proche que possible aux donnees. Concretement,
# on va minimiser la somme des erreurs carrees, c'est
# a dire \sum_i (y_i - ychapeau_i)^2 , ou ychapeau_i
# est m*x_i + b, i.e. la prediction de la ligne proposee.
squared_error <- function(theta, y, x) {
intercept <- theta[1]
slope <- theta[2]
y_pred <- intercept + slope*x
result <- sum((y - y_pred)^2)
return(result)
}
# En R, je peux faire des optimisations avec
# une fonction qui s'appelle optim() qui prend
# en entree une initialisation (les valeurs de
# depart pour, dans notre cas, b et m), un critere
# forme de fonction a MINIMISER (i.e. la "loss"),
# et des arguments supplementaires, et qui nous
# retourne des parametres qui, selon optim(), sont
# optimaux, dans notre cas, la ligne la plus "proche"
# a l'ensemble de donnees.
best_linear <- function(y, x) {
o <- optim(c(0,0), squared_error, y=y, x=x,
method="BFGS")
return(o$par)
}
# Je teste
best_linear(linear$logRT, linear$freq)
# possible de faire la vraie separation
# entre l'effet lineaire et l'effet de bruit/
# echantillonnage. Mais on peut montrer que,
# dans la limite, avec de plus en plus de
# donnees, on s'approche a la bonne reponse
# avec le critere erreur carree.
#
# On peut montrer aussi que s'il y a zero
# effet d'echantillonnage, on trouve
# exactement la bonne reponse.
linear_2 <- NULL
for (frequence in 2:9) {
new_response <- spr_ungram$logRT - frequence*0.5
new_data <- tibble::tibble(logRT=new_response,
freq=frequence)
linear_2 <- dplyr::bind_rows(linear_2, new_data)
}
best_linear(linear_2$logRT, linear_2$freq)
# R contient une fonction qui resolut le
# meme probleme (d'une autre maniere car
# il existe pour le modele lineaire simple
# une solution analytique)
lm(logRT ~ freq, linear)
lm(logRT ~ freq, linear_2)
lm(Response ~ Explanatory, nonlinear_1)
# On peut avoir deux ou plusieurs variables
# qui ont un effet lineaire sur nos donnees,
# qui (selon le modele lineaire) s'ajoutent, c'est
# a dire, par addition.
linear_multiple <- NULL
for (expl_1 in 2:9) {
for (expl_2 in seq(-0.7, 0.4, by=0.1)) {
new_responses <- sample(spr_ungram$logRT,
12, replace=T) +
expl_1*0.5 + expl_2*(-2)
new_table <- tibble::tibble(Explanatory_1=expl_1,
Explanatory_2=expl_2,
Response=new_responses)
linear_multiple <- dplyr::bind_rows(
linear_multiple, new_table)
}
}
ggplot2::ggplot(linear_multiple,
ggplot2::aes(x=Response)) +
ggplot2::geom_histogram() +
ggplot2::facet_grid(Explanatory_1 ~ Explanatory_2)
lm(Response ~ Explanatory_1 + Explanatory_2, data=linear_multiple)
# Si je plotte les deux effets individuellement,
# on peut voir concretement le sens de ces deux
# coefficients
plot_linear <- function(d, resp_var, expl_var) {
linear_parameters <- best_linear(d[[resp_var]], d[[expl_var]])
d_summary <- d %>%
dplyr::group_by(get(expl_var)) %>%
dplyr::summarize(meanResponse=mean(get(resp_var)),
medianResponse=median(get(resp_var))) %>%
dplyr::ungroup()
names(d_summary)[1] <- expl_var
p <- ggplot2::ggplot(d, ggplot2::aes_string(y=resp_var, x=expl_var)) +
ggplot2::geom_point() +
ggplot2::geom_abline(slope=linear_parameters[2], intercept=linear_parameters[1],
colour="blue") +
ggplot2::geom_point(data=d_summary, ggplot2::aes(y=meanResponse), size=3.5) +
ggplot2::geom_point(data=d_summary, ggplot2::aes(y=meanResponse),
colour="red", size=3)
return(p)
}
plot_linear(linear_multiple,
"Response", "Explanatory_1")
plot_linear(linear_multiple,
"Response", "Explanatory_2")
# Si je "code" les variables categoriques avec
# des valeurs numeriques, je peux souvent profiter
# de l'ensemble d'outils et de raisonnement relies
# aux modeles lineaires, pour poser des questions
# telles que "est-ce qu'il y a une difference
# de position entre ces deux groupes" (i.e. question
# t-test)
sprd <- spr
sprd$ConditionCode <- ifelse(sprd$Condition == "Grammatical",
0, 1)
dplyr::group_by(sprd, Condition) %>%
dplyr::summarize(meanLogRT=mean(logRT)) %>%
dplyr::ungroup()
m_opt <- best_linear(sprd$logRT, sprd$ConditionCode)
logit <- function(p) {
return(log(p/(1-p)))
}
ilogit <- function(z) {
return(1/(1+exp(-z)))
}
logit_loss <- function(theta, y, x) {
intercept <- theta[1]
slope <- theta[2]
z_pred <- intercept + slope*x
p_pred <- ilogit(z_pred)
ll <- sum(log((p_pred^y)*((1-p_pred)^(1-y))))
return(-ll)
}
best_linear <- function(y, x, cost) {
o <- optim(c(0,0), cost, y=y, x=x, method="BFGS")
return(o$par)
}
asd <- readr::read_csv("https://bit.ly/2zJh19E")
asd_summary <- dplyr::group_by(asd, Age_Month, Group) %>%
dplyr::summarize(percent_correct=mean(Correct))
ggplot2::ggplot(asd_summary,
ggplot2::aes(y=percent_correct, x=Age_Month)) +
ggplot2::geom_point() +
ggplot2::facet_grid(Group ~ .)
curve(ilogit, from=-9, to=9)
fit_asd <- best_linear(as.numeric(asd$Correct), asd$Age_Month,
logit_loss)
asd_summary_logit <- dplyr::group_by(asd, Age_Month) %>%
dplyr::summarize(logit_percent_correct=logit(mean(Correct)))
ggplot2::ggplot(asd_summary_logit,
ggplot2::aes(y=logit_percent_correct,
x=Age_Month)) +
ggplot2::geom_point() +
ggplot2::geom_abline(intercept=fit_asd[1],
slope=fit_asd[2])
fit_asd_lm <- glm(Correct ~ Age_Month, family="binomial", data=asd)
asd$Group_c <- ifelse(asd$Group == "Typically developing children", 0, 1)
fit_asd_mult <- glm(Correct ~ Age_Month + Group_c, family="binomial", data=asd)
asd_summary_logit_bygroup <-
dplyr::group_by(asd, Age_Month, Group) %>%
dplyr::summarize(logit_percent_correct=logit(mean(Correct)))
asd_coefs <- tibble::tibble(
Group=c("Typically developing children",
"ASD subjects"),
Intercept=c(coef(fit_asd_mult)[1],
coef(fit_asd_mult)[1] + coef(fit_asd_mult)[3]),
Age_Effect=c(coef(fit_asd_mult)[2])
)
ggplot2::ggplot(asd_summary_logit_bygroup,
ggplot2::aes(y=logit_percent_correct,
x=Age_Month)) +
ggplot2::geom_point() +
ggplot2::geom_abline(data=asd_coefs,
ggplot2::aes(intercept=Intercept, slope=Age_Effect)) +
ggplot2::facet_grid(Group ~ .)
z_h0 <- ifelse(
asd$Group == "ASD subjects",
coef(fit_asd_mult)[1] + coef(fit_asd_mult)[3],
coef(fit_asd_mult)[1]
)
p_h0 <- ilogit(z_h0)
N_SAMPLES <- 9999
statistics <- NULL
for (i in 1:N_SAMPLES) {
y_fake <- NULL
for (j in 1:nrow(asd)) {
y_fake[j] <- sample(c(0, 1), 1, prob=c(1-p_h0[j], p_h0[j]))
}
fit_fake <- glm(y_fake ~  asd$Age_Month + asd$Group_c, family="binomial")
statistics[i] <- coef(fit_fake)[2]
}
View(spr)
ggplot(data = spr) +
geom_point(mapping = aes(x = condition, y = RT))
library(ggplot2)
ggplot(data = spr) +
geom_point(mapping = aes(x = condition, y = RT))
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT))
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary", position = "dodge")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary", position = "dodge")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_bar(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT))
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = logRT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
lm(RT ~ Condition)
lm(RT ~ Condition, spr)
plot_linear(733.49, -60.44)
abline(733.49, -60.44)
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
lm(RT ~ Condition, spr)
abline(733.49, -60.44)
library(ggplot2)
library(ggplot2)
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
lm(RT ~ Condition, spr)
abline(733.49, -60.44)
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
ggplot(data = spr) +
geom_point(mapping = aes(x = Condition, y = RT), stat = "summary")
